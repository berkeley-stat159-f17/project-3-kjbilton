{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Overview\n",
    "- Load in data used in the analyses\n",
    "- Understand the structure, granularity, and quality of the data\n",
    "- Clean up the data for further inspection\n",
    "\n",
    "## Datasets\n",
    "1. **Oakland neighborhoods**\n",
    "    - GeoJSON format data to plot different neighborhoods in Oakland. The idea here is to be able to aggregate any values of interest (e.g., incidents of grafitti) by easily-identifiable neighborhoods.\n",
    "1. **Oakland city service requests**\n",
    "    - CSV file containing requests (e.g., potholes, illegal dumping, etc.) from residents.\n",
    "1. **Residential zones within 300 feet of industrial zones**\n",
    "    - GeoJSON data that shows areas in which residents live very close to industrial zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard tools for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tools specific for geospatial data analysis\n",
    "from shapely.geometry import shape, mapping, Point, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "# Tools from the Python Standard Library\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at files that are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../data/'\n",
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Oakland neighborhood classification\n",
    "- A GeoJSON file classifying the areas in Oakland into neighborhoods was pulled from https://data.oaklandnet.com/Property/Oakland-Neighborhoods/7zky-kcq9 on 22/11/17.\n",
    "- The downloaded file was renamed, replacing spaces with underscores, and setting all letters to lowercase for convenience.\n",
    "\n",
    "Let's read in this GeoJSON file:\n",
    "\n",
    "### Note\n",
    "It wasn't trivial to get this working! I spent quite some time hacking to get this to come out right (ultimately, it just came down to finding the right versions to use). Reading GeoJSON into Geopandas DataFrames should be straightforward, but I was met with quite a few errors. After doing some tracking, I found that the right combination was using installing `shapely` and `geopandas` from `pip` instead of `conda-forge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = gpd.read_file(DATADIR + 'oakland_neighborhoods.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(neighborhoods.head())\n",
    "display(neighborhoods.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an empty `description` column that we can remove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neighborhoods['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, this GeoDataFrame contains both points and polygons. The points are used as markers (e.g., on interactive maps), while the polygons actually give us the shape. Let's move all the points to a separate column called `centers`, so we can have a single point to characterize the neighborhood, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a temporary DataFrame only containing points\n",
    "neighborhood_centers = neighborhoods[(neighborhoods.geom_type == 'Point')]\n",
    "\n",
    "# Remove points from the neighborhood DataFrame\n",
    "neighborhoods = neighborhoods[~(neighborhoods.geom_type == 'Point')]\n",
    "\n",
    "# Reset the indexing to 0\n",
    "neighborhoods.reset_index(inplace=True)\n",
    "del neighborhoods['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the longitude and latitude from each center coordinate, and add that to the main neighborhoods DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "center_lon = neighborhood_centers['geometry'].apply(lambda x: x.coords[0][0])\n",
    "center_lat = neighborhood_centers['geometry'].apply(lambda x: x.coords[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods['center_lon'] = center_lon\n",
    "neighborhoods['center_lat'] = center_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check these neighborhoods out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "neighborhoods.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save this to file for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The .shp format saves several files, so let's make a special subdirectory for that\n",
    "if not os.path.exists(DATADIR + 'neighborhoods'):\n",
    "    os.mkdir(DATADIR + 'neighborhoods')\n",
    "\n",
    "\n",
    "neighborhoods.to_file(DATADIR + 'neighborhoods/oakland_neighborhoods_clean.shp',\n",
    "                      driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this just gives us the shapes of our neighborhoods without any context. Later on, I will plot these neighborhoods on top of a map (e.g., satellite images) so we get an idea of where these are located with respect to other features we are familiar with. To do this, we will use `basemap`. It's worth noting that `basemap` is being replaced with `cartopy`, but since I'm somewhat familiar with `basemap` for the time being :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same coordinates from the above plot to get our $x$ and $y$ limits. In `basemap`, these will be referred to as the lower (upper) left (right) corner latitude (longitude) or llcrnlat, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. City Service Requests\n",
    "- An Excel Spreadsheet containing service requests to the city was pulled on the afternoon of 11 December 2017. This record is regularly updated and contains the following information of interest:\n",
    "    1. Request ID\n",
    "    1. Date and time at which the request was registered in the system\n",
    "    1. Source of service request (i.e., call, email, website)\n",
    "    1. Description\n",
    "    1. Request category (e.g., GRAFFITI)\n",
    "    1. Request location (address and/or GPS coordinates)\n",
    "    1. Status (open, closed, cancelled, etc.)\n",
    "    1. Date and time at which the request was closed in the system\n",
    "- The purpose for considering this data is to look at the frequency at which requests are made in different neighborhoods, as well as the distribution of times it takes to resolve issues.\n",
    "- Now that I think about it, this is quite a rich dataset in itself, and could be the basis of this project alone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_requests = pd.read_csv(DATADIR + 'Service_requests_received_by_the_Oakland_Call_Center.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I'll drop the `REFERREDTO`, `SRX`, `SRY`, `COUNCILDISTRICT`, and `BEAT` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.drop(columns=['REFERREDTO', 'SRX', 'SRY', 'COUNCILDISTRICT', 'BEAT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from looking at these, we can see that many requests look pretty boring (e.g., reporting missing trash pickup). Let's explore this more to see if we can find data that can tell us more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(service_requests['REQCATEGORY'].unique())\n",
    "display(service_requests['SOURCE'].unique())\n",
    "display(service_requests['STATUS'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the unfunded requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service_requests[service_requests['STATUS'] == 'UNFUNDED'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get GPS Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want the GPS coordinates for easier plotting later on. Let's do some regex-ing to clean those addresses/coordinates up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_requests['REQADDRESS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a regex expression that can be used to pull GPS coordinates from the address column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.findall('[\\d.]+, [\\-\\d.]+', service_requests['REQADDRESS'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a function to perform this search and also return a tuple of GPS coordinates for us. I included this function in a script located at `scripts/oaktext.py`. The purpose for that is reuse, and the ability to test.*\n",
    "\n",
    "<sub>* This is a bit of a contrived example for unit testing. </sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the module that the scripts are stored in\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "# Import the module for getting coordinates\n",
    "from oaktext import get_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coords(service_requests['REQADDRESS'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests['coordinates'] = service_requests['REQADDRESS'].apply(get_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries with coordinates:', service_requests[service_requests['coordinates'].notnull()].shape[0])\n",
    "print('Number of entries without coordinates:', service_requests[service_requests['coordinates'].isna()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit ourselves to the entries that have coordinates for us to plot (using the addresses provided is completely possible, but beyond the scope of our current analysis). As we see above, we still have a good amount of data to play with. It's worth noting that selecting only those with GPS coordinates may in fact be introducing a bias in our results, or it may in fact be a negiligble effect (e.g., the people responsible for data entry may not have entered the coordinates...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests = service_requests[service_requests['coordinates'].notnull()]\n",
    "print(service_requests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we are not using the address, let's just drop that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.drop(columns='REQADDRESS', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dates/times to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another piece of data that may be of interest to us is how long it took to close the request. For example, we can geospatially map out how long it took to close requests. To do this, let's first make sure the times are all in a common format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.loc[:, 'DATETIMEINIT'] = pd.to_datetime(service_requests['DATETIMEINIT'],\n",
    "                                                         format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "service_requests.loc[:, 'DATETIMECLOSED'] = pd.to_datetime(service_requests['DATETIMECLOSED'],\n",
    "                                                           format=\"%m/%d/%Y %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the range of the dates here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_requests['DATETIMEINIT'].min(), service_requests['DATETIMEINIT'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat, we have about 8 years of data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.loc[:, 'time_to_close'] = (service_requests['DATETIMECLOSED']\n",
    "                                            - service_requests['DATETIMEINIT']).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.time_to_close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service_requests.sort_values(by='time_to_close', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that sometimes it takes years to close these! However, these are just the ones that are still open. If a request had never been closed, its value for `DATETIMECLOSED` will be `NaT` (i.e., not a time). As a result, we probably want a variable that gives us the time since opening. To do this, we can find the difference in time from when this was downloaded and when the request was opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset was downloaded on 11 Dec. 2017\n",
    "t_0 = pd.datetime(2017, 12, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.loc[:, 'time_since_init'] = (t_0 - service_requests['DATETIMEINIT']).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in a good state to run further analyses on these data. Let's save it for further inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTSDIR = '../results/'\n",
    "if not os.path.exists(RESULTSDIR):\n",
    "    os.mkdir(RESULTSDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_requests.to_hdf(RESULTSDIR + '01-service_requests.h5', 'service_requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Residential areas within 300 feet of industrial zones\n",
    "- A GeoJSON file classifying the areas in Oakland into neighborhoods was pulled from https://data.oaklandnet.com/Economic-Development/Residential-Zones-300-ft-of-Industrial-Areas/d3re-jdqr on 22/11/17.\n",
    "- The downloaded file was renamed, replacing spaces with underscores, and setting all letters to lowercase for convenience.\n",
    "\n",
    "Let's read in this GeoJSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_industrial = gpd.read_file(DATADIR + 'residential_zones_300_ft_of_industrial_areas.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_industrial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay these zones on the neighborhood map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_industrial.plot(color='r', ax=ax);\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows residential areas, within the blue neighborhoods, that are close (less than 300 feet!) to industrial zones. This will be of particular interest when considering air quality data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oakland]",
   "language": "python",
   "name": "conda-env-oakland-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
